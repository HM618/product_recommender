{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.clustering import LDA, KMeans\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (ps.sql.SparkSession.builder\n",
    "        .master(\"local[3]\")\n",
    "        .appName(\"capstone\")\n",
    "        .getOrCreate()\n",
    "        )\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('s3a://capstone-3/data/products_art_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0', axis=1,inplace=True)\n",
    "spark_df = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- vendor_variant_id: long (nullable = true)\n",
      " |-- vendor_id: long (nullable = true)\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- product_description: string (nullable = true)\n",
      " |-- vendor_name: string (nullable = true)\n",
      " |-- taxonomy_name: string (nullable = true)\n",
      " |-- taxonomy_id: double (nullable = true)\n",
      " |-- weblink: string (nullable = true)\n",
      " |-- color: string (nullable = true)\n",
      " |-- material: string (nullable = true)\n",
      " |-- pattern: string (nullable = true)\n",
      " |-- is_returnable: boolean (nullable = true)\n",
      " |-- ship_surcharge: double (nullable = true)\n",
      " |-- is_assembly_required: boolean (nullable = true)\n",
      " |-- is_feed: long (nullable = true)\n",
      " |-- commission_tier: string (nullable = true)\n",
      " |-- inventory_type: string (nullable = true)\n",
      " |-- division: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- sale_price: double (nullable = true)\n",
      " |-- combo: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|       product_title|               combo|\n",
      "+--------------------+--------------------+\n",
      "|Framed Canvas Pri...|Framed Canvas Pri...|\n",
      "|Framed Print, Abs...|Framed Print, Abs...|\n",
      "|Janel Foo Glasswo...|Janel Foo Glasswo...|\n",
      "|The Arts Capsule ...|The Arts Capsule ...|\n",
      "|Native Maps - Aus...|Native Maps - Aus...|\n",
      "|Framed Print, Tur...|Framed Print, Tur...|\n",
      "|Sarah Campbell Wa...|Sarah Campbell Wa...|\n",
      "|Framed Print, Ope...|Framed Print, Ope...|\n",
      "|Framed Print, Mid...|Framed Print, Mid...|\n",
      "|The Arts Capsule ...|The Arts Capsule ...|\n",
      "|Canvas Print - Ab...|Canvas Print - Ab...|\n",
      "|Ashley Mary Art L...|Ashley Mary Art L...|\n",
      "|The Arts Capsule ...|The Arts Capsule ...|\n",
      "|Ashley Mary Balan...|Ashley Mary Balan...|\n",
      "|The Arts Capsule ...|The Arts Capsule ...|\n",
      "|The Arts Capsule ...|The Arts Capsule ...|\n",
      "|Felt Wall Art, Bl...|Felt Wall Art, Bl...|\n",
      "|Minted for west e...|Minted for west e...|\n",
      "|Erik Barthels Pri...|Erik Barthels Pri...|\n",
      "|The Arts Capsule ...|The Arts Capsule ...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.select('product_title','combo').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_pipeline():\n",
    "    tokenizer = Tokenizer(inputCol=\"combo\", outputCol=\"words\")\n",
    "    hashingTF = HashingTF(inputCol='words', outputCol=\"rawFeatures\", numFeatures=20)\n",
    "    idf = IDF(inputCol='rawFeatures', outputCol=\"features\")\n",
    "    pipeline = Pipeline(stages=[tokenizer, hashingTF, idf])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = tfidf_pipeline()\n",
    "features_df = pipeline.fit(spark_df).transform(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmeans_rec(dataset,item_id, num_recs = 3):\n",
    "    kmeans = KMeans(k=10)\n",
    "    model = kmeans.fit(dataset)\n",
    "    result = model.transform(dataset)\n",
    "    labels = result.select('prediction')\n",
    "    item_cluster_label = result.filter(col('vendor_variant_id') == str(item_id)).select('prediction').collect()[0][0]\n",
    "    cluster_members = result.filter(col('prediction') == item_cluster_label)\n",
    "    cluster_members.select('product_title').show(num_recs)\n",
    "    return result\n",
    "\n",
    "def get_centers(model):   \n",
    "    # Evaluate clustering by computing Within Set Sum of Squared Errors.\n",
    "    wssse = model.computeCost(dataset)\n",
    "    print(\"Within Set Sum of Squared Errors = \" + str(wssse))\n",
    "\n",
    "    # Shows the result.\n",
    "    centers = model.clusterCenters()\n",
    "    print(\"Cluster Centers: \")\n",
    "    for center in centers:\n",
    "        print(center)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|       product_title|\n",
      "+--------------------+\n",
      "|Native Maps - Aus...|\n",
      "|Sarah Campbell Wa...|\n",
      "|Framed Canvas Pri...|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = get_kmeans_rec(features_df, 7432702)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.ballarddesigns.com/antique-aviary-giclee-prints/wall-decor/all-art/225658'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_id = 7432702\n",
    "result.filter(col('vendor_variant_id') == str(item_id)).select('product_title','weblink').collect()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = 100.00\n",
    "max = 500.00\n",
    "restrict_min = spark_df.where(col('sale_price') > min)\n",
    "restricted = restrict_min.where(col('sale_price') < max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[vendor_variant_id: bigint, vendor_id: bigint, product_title: string, product_description: string, vendor_name: string, taxonomy_name: string, taxonomy_id: double, weblink: string, color: string, material: string, pattern: string, is_returnable: boolean, ship_surcharge: double, is_assembly_required: boolean, is_feed: bigint, commission_tier: string, inventory_type: string, division: string, category: string, price: double, sale_price: double, combo: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restricted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_row = spark_df.filter(col('vendor_variant_id') == str(item_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[vendor_variant_id: bigint, vendor_id: bigint, product_title: string, product_description: string, vendor_name: string, taxonomy_name: string, taxonomy_id: double, weblink: string, color: string, material: string, pattern: string, is_returnable: boolean, ship_surcharge: double, is_assembly_required: boolean, is_feed: bigint, commission_tier: string, inventory_type: string, division: string, category: string, price: double, sale_price: double, combo: string]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105697"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restricted.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_restricted = restricted.union(item_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105698"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_restricted.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
